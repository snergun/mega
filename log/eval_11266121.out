usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...
conda: error: argument COMMAND: invalid choice: 'deactivate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'build', 'content-trust', 'convert', 'debug', 'develop', 'doctor', 'index', 'inspect', 'metapackage', 'render', 'repoquery', 'skeleton', 'env', 'verify', 'token', 'repo', 'server')
Running "module reset". Resetting modules to system default. The following $MODULEPATH directories have been removed: None

The following have been reloaded with a version change:
  1) cuda/11.8.0 => cuda/11.3.1

2025-07-30 18:24:40 | INFO | fairseq_cli.eval_lm | Namespace(add_bos_token=False, all_gather_list_size=16384, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', chunk_nums=2, context_window=0, cpu=False, criterion='cross_entropy', data='data/wikitext-103', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, max_sentences=None, max_target_positions=None, max_tokens=5000000, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{"decoder_chunk_size": 2048,"max_tokens_valid": 5000000}', model_parallel_size=1, no_progress_bar=False, no_seed_provided=True, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer=None, output_dictionary_size=-1, output_word_probs=True, output_word_stats=False, past_target=False, path='checkpoints/1024_wt103/model.pt', profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, required_batch_size_multiple=8, results_path='checkpoints/1024_wt103/results/', sample_break_mode='complete', seed=1, self_target=False, shard_id=0, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=1024, task='language_modeling', tensorboard_logdir='', test_chunk_size=2048, threshold_loss_scale=None, tokenizer=None, tokens_per_sample=1024, tpu=False, user_dir=None, valid_block='splits:10', variant_block_multiple_max=1, variant_block_multiple_min=1, wandb_entity=None, wandb_id=None, wandb_project=None, warmup_updates=0)
2025-07-30 18:24:41 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types
2025-07-30 18:24:41 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/1024_wt103/model.pt
2025-07-30 18:25:28 | INFO | fairseq_cli.eval_lm | Loaded args!
2025-07-30 18:25:28 | INFO | fairseq_cli.eval_lm | Namespace(activation_dropout=0.1, activation_fn='silu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=True, adaptive_input_cutoff='20000,60000', adaptive_input_factor=4, adaptive_softmax_cutoff='20000,60000', adaptive_softmax_dropout=0.2, adaptive_softmax_factor=4, add_bos_token=False, all_gather_list_size=16384, arch='mega_lm_adaptive_big', attention_activation_fn='softmax', attention_dropout=0.1, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', chunk_nums=2, clip_mode='total', clip_norm=0.25, context_window=0, cpu=False, criterion='cross_entropy', curriculum=0, data='data/wikitext-103', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_chunk_size=2048, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_hidden_dim=2048, decoder_input_dim=1024, decoder_layers=16, decoder_n_dim=16, decoder_z_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, end_learning_rate=0.0, fast_stat_sync=False, feature_dropout=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', hidden_dropout=0.1, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.005], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_target_positions=None, max_tokens=5000000, max_tokens_valid=5000000, max_update=400000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_overrides='{"decoder_chunk_size": 2048,"max_tokens_valid": 5000000}', model_parallel_size=1, no_affine_final_norm=True, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=True, normalization_type='layernorm', normalize_before=True, normalize_embedding=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer=None, optimizer_overrides='{}', output_dictionary_size=-1, output_word_probs=True, output_word_stats=False, past_target=False, path='checkpoints/1024_wt103/model.pt', patience=-1, profile=False, quantization_config_path=None, quiet=False, rel_pos_bias='rotary', remove_bpe=None, report_ema_alpha=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path='checkpoints/1024_wt103/results/', sample_break_mode='complete', save_dir='saved_models/mega/lm/1024_rotary_softmax_noaffine_tot400k_complete_clip0.25_1024_wd0.1_wt103_softmax_silu_layernorm_ndim16_lr5e-3_warmup24000_seed42', save_interval=1, save_interval_updates=0, seed=1, self_target=False, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, softmax_batch=1024, stop_min_lr=-1, stop_time_hours=0, task='language_modeling', tensorboard_logdir='', test_chunk_size=2048, test_subset='test', threshold_loss_scale=None, tie_adaptive_proj=True, tie_adaptive_weights=True, tokenizer=None, tokens_per_sample=2048, total_num_update=400000, tpu=False, train_subset='train', truncation_length=8192, update_freq=[1], use_bmuf=False, use_old_adam=False, user_dir=None, valid_block='splits:10', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, variant_block_multiple_max=1, variant_block_multiple_min=1, wandb_entity=None, wandb_id=None, wandb_project=None, warmup_init_lr=1e-07, warmup_power=1, warmup_updates=0, weight_decay=0.1, write_out_alpha=False)
2025-07-30 18:25:28 | INFO | fairseq.data.data_utils | loaded 4358 examples from: data/wikitext-103/test
2025-07-30 18:25:35 | INFO | fairseq_cli.eval_lm | num. model params: 252237824
2025-07-30 18:25:36 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types
Evaluated 245569 tokens in 11.9s (20658.21 tokens/s)
Loss (base 2): 4.1759, Perplexity: 18.07
